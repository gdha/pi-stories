{"config":{"lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Welcome to Raspberry PI k3s stories \u00b6 You can use the editor on GitHub to maintain and preview the content for your website in Markdown files. Whenever you commit to this repository, GitHub Pages will run Jekyll to rebuild the pages in your site, from the content in your Markdown files. Markdown Syntax \u00b6 Markdown is a lightweight and easy-to-use syntax for styling your writing. It includes conventions for Syntax highlighted code block # Header 1 ## Header 2 ### Header 3 - Bulleted - List 1. Numbered 2. List **Bold** and _Italic_ and `Code` text [Link](url) and ![Image](src) For more details see GitHub Flavored Markdown . Mkdocs Themes with GitHub Pages \u00b6 Read how to set-up the site with GitHub pages Support or Contact \u00b6 Having trouble with Pages? Check out our documentation or contact support and we\u2019ll help you sort it out.","title":"WELCOME"},{"location":"#welcome_to_raspberry_pi_k3s_stories","text":"You can use the editor on GitHub to maintain and preview the content for your website in Markdown files. Whenever you commit to this repository, GitHub Pages will run Jekyll to rebuild the pages in your site, from the content in your Markdown files.","title":"Welcome to Raspberry PI k3s stories"},{"location":"#markdown_syntax","text":"Markdown is a lightweight and easy-to-use syntax for styling your writing. It includes conventions for Syntax highlighted code block # Header 1 ## Header 2 ### Header 3 - Bulleted - List 1. Numbered 2. List **Bold** and _Italic_ and `Code` text [Link](url) and ![Image](src) For more details see GitHub Flavored Markdown .","title":"Markdown Syntax"},{"location":"#mkdocs_themes_with_github_pages","text":"Read how to set-up the site with GitHub pages","title":"Mkdocs Themes with GitHub Pages"},{"location":"#support_or_contact","text":"Having trouble with Pages? Check out our documentation or contact support and we\u2019ll help you sort it out.","title":"Support or Contact"},{"location":"pi-stories/","text":"PI4 Stories \u00b6 Raspberry Pi 4 cluster Series - Basic OS configuration \u00b6 Before we can build a PI 4 cluster using kubernetes software of some kind (most likely k3s) we need to buy the required hardware to begin with. In our case we decided to go for 5 Raspberry Pi's type 4 with 4 GB RAM. We leave the exercise to you what size of SD card you want (more GB cost more money, but gives you some room for expansion later on). We also bought some small USB sticks (type SanDisk Ultra Fit USB 3.1 flash drive 128 GB) for building an object oriented file system (but that is for a later series). Also, we bought some PI cases with fans built-in to keep the processor cool as we know kubernetes may heat up the processor [1]. We noticed that the temperature of a case with fans is around 40 degrees Celsius where with a metal case only (without fans) it is around 60 degrees Celsius. Decided to buy quickly an extra case with fans as it is worth its money. We were charmed with Ubuntu 20 series software and downloaded the Pi4 64-bit version and used the dd command to burn it onto the SD cards [2]. Link it all together to start a Pi computer one at the time. The first time we hooked the micro-HDMI to a TV-screen so we could watch the first kick off and to see everything looked right. Also, we needed to reset the default password of the built-in account named 'ubuntu'. By default the Pi computer is using DHCP for retrieving IP addresses, but we want to assign a static IPv4 address. Therefore, think ahaid and use something like this: cat >> /etc/hosts <<EOF # PI cluster 192.168.0.201 n1 192.168.0.202 n2 192.168.0.203 n3 192.168.0.204 n4 192.168.0.205 n5 EOF Of course, change the IPv4 addresses to your local taste. It is also a good idea to hard-code your local timezone, in our case we choose for Europe/Brussels, e.g. timedatectl set-timezone Europe/Brussels The kubernetes cluster (not yet of course) prefers not having IPv6 active, therefore, disable it via: echo \"net.ipv6.conf.all.disable_ipv6 = 1\" >> /etc/sysctl.conf sysctl -p And, check the time settings: systemctl status systemd-timesyncd To disable DHCP at next restart execute the following: cat > /etc/cloud/cloud.cfg.d/99-disable-network-config.cfg <<EOF # network: {config: disabled} network: ethernets: eth0: dhcp4: true optional: true version: 2 EOF And, lets hide the original netplan yaml file: mkdir /etc/netplan/.hide mv /etc/netplan/50-cloud-init.yaml /etc/netplan/.hide The following steps differ node per node as we will define the hostname and fix the IPv4 address: hostnamectl set-hostname n1 Be careful, to use the correct hostname in above command. To define your permanent IPv4 address create your own netplan configuration as follow: cat > /etc/netplan/01-netcfg.yaml <<EOF # This file describes the network interfaces available on your system # For more information, see netplan(5). network: version: 2 renderer: networkd ethernets: eth0: dhcp4: no # IP address/subnet mask addresses: [192.168.0.201/24] # default gateway gateway4: 192.168.0.1 nameservers: # name server this host refers addresses: [192.168.0.1,8.8.8.8] dhcp6: no EOF Then, edit the file /etc/netplan/01-netcfg.yaml to adjust the correct IPv4 address of the node and also modify the gateway IPv4 address to your needs. On your laptop (or control server) we also add the IPv4 addresses of our Pi systems to the /etc/hosts file and to make your live easy copy your public OpenSSH keys to the ubuntu account like: ssh-copy-id ubuntu@n[1-5] Reboot this Pi computer and try to login via your laptop using ssh ubuntu@n1 OK so far for the first part, but just want to share picture of our setup with 5 Raspberry Pi's 4 nodes n[1-5]: References: \u00b6 [1] Joy-it Armor case \"Block Active\" for Raspberry Pi 4 [2] Download your Ubuntu Pi image Edit history \u00b6 Initial post on 01/Jul/2020 Updated title on 09/Sep/2020","title":"Raspberry Pi 4 Basic OS Configuration"},{"location":"pi-stories/#pi4_stories","text":"","title":"PI4 Stories"},{"location":"pi-stories/#raspberry_pi_4_cluster_series_-_basic_os_configuration","text":"Before we can build a PI 4 cluster using kubernetes software of some kind (most likely k3s) we need to buy the required hardware to begin with. In our case we decided to go for 5 Raspberry Pi's type 4 with 4 GB RAM. We leave the exercise to you what size of SD card you want (more GB cost more money, but gives you some room for expansion later on). We also bought some small USB sticks (type SanDisk Ultra Fit USB 3.1 flash drive 128 GB) for building an object oriented file system (but that is for a later series). Also, we bought some PI cases with fans built-in to keep the processor cool as we know kubernetes may heat up the processor [1]. We noticed that the temperature of a case with fans is around 40 degrees Celsius where with a metal case only (without fans) it is around 60 degrees Celsius. Decided to buy quickly an extra case with fans as it is worth its money. We were charmed with Ubuntu 20 series software and downloaded the Pi4 64-bit version and used the dd command to burn it onto the SD cards [2]. Link it all together to start a Pi computer one at the time. The first time we hooked the micro-HDMI to a TV-screen so we could watch the first kick off and to see everything looked right. Also, we needed to reset the default password of the built-in account named 'ubuntu'. By default the Pi computer is using DHCP for retrieving IP addresses, but we want to assign a static IPv4 address. Therefore, think ahaid and use something like this: cat >> /etc/hosts <<EOF # PI cluster 192.168.0.201 n1 192.168.0.202 n2 192.168.0.203 n3 192.168.0.204 n4 192.168.0.205 n5 EOF Of course, change the IPv4 addresses to your local taste. It is also a good idea to hard-code your local timezone, in our case we choose for Europe/Brussels, e.g. timedatectl set-timezone Europe/Brussels The kubernetes cluster (not yet of course) prefers not having IPv6 active, therefore, disable it via: echo \"net.ipv6.conf.all.disable_ipv6 = 1\" >> /etc/sysctl.conf sysctl -p And, check the time settings: systemctl status systemd-timesyncd To disable DHCP at next restart execute the following: cat > /etc/cloud/cloud.cfg.d/99-disable-network-config.cfg <<EOF # network: {config: disabled} network: ethernets: eth0: dhcp4: true optional: true version: 2 EOF And, lets hide the original netplan yaml file: mkdir /etc/netplan/.hide mv /etc/netplan/50-cloud-init.yaml /etc/netplan/.hide The following steps differ node per node as we will define the hostname and fix the IPv4 address: hostnamectl set-hostname n1 Be careful, to use the correct hostname in above command. To define your permanent IPv4 address create your own netplan configuration as follow: cat > /etc/netplan/01-netcfg.yaml <<EOF # This file describes the network interfaces available on your system # For more information, see netplan(5). network: version: 2 renderer: networkd ethernets: eth0: dhcp4: no # IP address/subnet mask addresses: [192.168.0.201/24] # default gateway gateway4: 192.168.0.1 nameservers: # name server this host refers addresses: [192.168.0.1,8.8.8.8] dhcp6: no EOF Then, edit the file /etc/netplan/01-netcfg.yaml to adjust the correct IPv4 address of the node and also modify the gateway IPv4 address to your needs. On your laptop (or control server) we also add the IPv4 addresses of our Pi systems to the /etc/hosts file and to make your live easy copy your public OpenSSH keys to the ubuntu account like: ssh-copy-id ubuntu@n[1-5] Reboot this Pi computer and try to login via your laptop using ssh ubuntu@n1 OK so far for the first part, but just want to share picture of our setup with 5 Raspberry Pi's 4 nodes n[1-5]:","title":"Raspberry Pi 4 cluster Series - Basic OS configuration"},{"location":"pi-stories/#references","text":"[1] Joy-it Armor case \"Block Active\" for Raspberry Pi 4 [2] Download your Ubuntu Pi image","title":"References:"},{"location":"pi-stories/#edit_history","text":"Initial post on 01/Jul/2020 Updated title on 09/Sep/2020","title":"Edit history"},{"location":"pi-stories2/","text":"PI4 Stories \u00b6 Raspberry Pi 4 cluster Series - Prepare for kubernetes installation \u00b6 Add account with Secure Shell keys and common software packages \u00b6 It is important that my account is created on each host with the requires secure shell keys. Also, we install what we think are required software packages on each host: vim git rsync acl dnsutils dphys-swapfile python-is-python3 sshpass ca-certificates curl gnupg-agent software-properties-common jq To get going first install git on the system where you start ansible playbooks (in our case it is host n5) and afterwards, clone the playbook pi4-cluster-ansible-roles . Do check the inventory.yml file and add you preferences. The playbook will also disable swap on each host, which is a requirement for kubernetes. Compile ARM side libraries for interfacing to Raspberry Pi GPU \u00b6 Download the source code from 2 . Compile and install these binaries on the host from where you will use the playbook. In my case its was host n5 (do not forget to install ansible ). Run the ansible playbook provision.yml \u00b6 $ ansible-playbook provision.yml -k --vault-password-file .my_password SSH password: PLAY [all] ************************************************************************************************************************************* TASK [Gathering Facts] ************************************************************************************************************************* ok: [n5] ok: [n3] ok: [n2] ok: [n4] ok: [n1] TASK [user : debug] **************************************************************************************************************************** ok: [n1] => { \"msg\": \"creating user gdha and OpenSSH public key distribution\" } ok: [n2] => { \"msg\": \"creating user gdha and OpenSSH public key distribution\" } ok: [n3] => { \"msg\": \"creating user gdha and OpenSSH public key distribution\" } ok: [n4] => { \"msg\": \"creating user gdha and OpenSSH public key distribution\" } ok: [n5] => { \"msg\": \"creating user gdha and OpenSSH public key distribution\" } TASK [user : Creating admin group] ************************************************************************************************************* ok: [n3] ok: [n1] ok: [n4] ok: [n2] ok: [n5] TASK [user : Add group gdha (1001)] ************************************************************************************************************ ok: [n1] ok: [n2] ok: [n3] ok: [n4] ok: [n5] TASK [user : Add user 'gdha' with specific uid (1001) and group 'gdha' (1001) and secondary group 'admin'] ************************************* ok: [n5] ok: [n2] ok: [n3] ok: [n1] ok: [n4] TASK [user : Create the /home/gdha/.ssh directory] ********************************************************************************************* ok: [n2] ok: [n1] ok: [n3] ok: [n4] ok: [n5] TASK [user : Copy /home/gdha/.ssh/id_rsa.pub to remote nodes] ********************************************************************************** ok: [n2] ok: [n3] ok: [n1] ok: [n4] ok: [n5] TASK [user : Append public ssh key of gdha to authorized_keys] ********************************************************************************* changed: [n1] => (item=/home/gdha/.ssh/id_rsa.pub) changed: [n4] => (item=/home/gdha/.ssh/id_rsa.pub) changed: [n2] => (item=/home/gdha/.ssh/id_rsa.pub) changed: [n3] => (item=/home/gdha/.ssh/id_rsa.pub) ok: [n5] => (item=/home/gdha/.ssh/id_rsa.pub) TASK [user : Create /etc/sudoers.d/gdha-sudoers file] ****************************************************************************************** ok: [n1] ok: [n2] ok: [n3] ok: [n4] ok: [n5] TASK [base : Set /etc/hosts for other nodes] *************************************************************************************************** ok: [n1] => (item=n2) ok: [n2] => (item=n1) ok: [n3] => (item=n1) ok: [n4] => (item=n1) ok: [n5] => (item=n1) ok: [n1] => (item=n3) ok: [n2] => (item=n3) ok: [n3] => (item=n2) ok: [n4] => (item=n2) ok: [n5] => (item=n2) ok: [n1] => (item=n4) ok: [n2] => (item=n4) ok: [n4] => (item=n3) ok: [n3] => (item=n4) ok: [n5] => (item=n3) ok: [n1] => (item=n5) ok: [n2] => (item=n5) ok: [n4] => (item=n5) ok: [n3] => (item=n5) ok: [n5] => (item=n4) TASK [base : Install common packages] ********************************************************************************************************** ok: [n5] changed: [n2] changed: [n3] changed: [n4] changed: [n1] TASK [base : Set default locale] *************************************************************************************************************** ok: [n1] ok: [n2] ok: [n3] ok: [n4] ok: [n5] TASK [base : Enable locale] ******************************************************************************************************************** ok: [n2] ok: [n1] ok: [n3] ok: [n4] ok: [n5] TASK [rpi : Create directory /opt/vc/bin] ****************************************************************************************************** ok: [n1] ok: [n2] ok: [n3] ok: [n4] ok: [n5] TASK [rpi : copy tvservice to /opt/vc/bin] ***************************************************************************************************** ok: [n1] ok: [n2] ok: [n3] ok: [n4] ok: [n5] TASK [rpi : Create the /opt/vc/lib directory] ************************************************************************************************** ok: [n1] ok: [n2] ok: [n3] ok: [n4] ok: [n5] TASK [rpi : Copy /opt/vc/lib/libvchiq_arm.so] ************************************************************************************************** ok: [n1] ok: [n2] ok: [n3] ok: [n4] ok: [n5] TASK [rpi : Copy /opt/vc/lib/libvcos.so] ******************************************************************************************************* ok: [n1] ok: [n2] ok: [n3] ok: [n4] ok: [n5] TASK [rpi : add /opt/vc/lib to /etc/ld.so.conf file] ******************************************************************************************* ok: [n1] ok: [n2] ok: [n3] ok: [n4] ok: [n5] TASK [rpi : Run ldconfig] ********************************************************************************************************************** changed: [n2] changed: [n1] changed: [n3] changed: [n4] changed: [n5] TASK [rpi : Check if HDMI is on] *************************************************************************************************************** ok: [n1] ok: [n2] ok: [n3] ok: [n4] ok: [n5] TASK [rpi : Switch off HDMI] ******************************************************************************************************************* changed: [n1] changed: [n2] changed: [n3] changed: [n4] changed: [n5] TASK [rpi : Ensure rc.local exists] ************************************************************************************************************ changed: [n1] changed: [n2] changed: [n3] changed: [n4] changed: [n5] TASK [rpi : Switch off HDMI on boot] *********************************************************************************************************** ok: [n1] ok: [n2] ok: [n3] ok: [n4] ok: [n5] TASK [os : Set hostname] *********************************************************************************************************************** ok: [n2] ok: [n3] ok: [n1] ok: [n4] ok: [n5] TASK [os : Set /etc/hosts hostname] ************************************************************************************************************ ok: [n1] ok: [n2] ok: [n3] ok: [n4] ok: [n5] TASK [os : Check if swap is enabled] *********************************************************************************************************** changed: [n1] changed: [n2] changed: [n3] changed: [n4] changed: [n5] TASK [os : Disable swap] *********************************************************************************************************************** changed: [n1] => (item=dphys-swapfile swapoff) changed: [n2] => (item=dphys-swapfile swapoff) changed: [n3] => (item=dphys-swapfile swapoff) changed: [n4] => (item=dphys-swapfile swapoff) changed: [n5] => (item=dphys-swapfile swapoff) changed: [n1] => (item=dphys-swapfile uninstall) changed: [n2] => (item=dphys-swapfile uninstall) changed: [n3] => (item=dphys-swapfile uninstall) changed: [n4] => (item=dphys-swapfile uninstall) changed: [n5] => (item=dphys-swapfile uninstall) changed: [n2] => (item=update-rc.d dphys-swapfile disable) changed: [n3] => (item=update-rc.d dphys-swapfile disable) changed: [n1] => (item=update-rc.d dphys-swapfile disable) changed: [n4] => (item=update-rc.d dphys-swapfile disable) changed: [n5] => (item=update-rc.d dphys-swapfile disable) TASK [os : Add users to passwordless sudoers.] ************************************************************************************************* ok: [n1] => (item=gdha) ok: [n2] => (item=gdha) ok: [n3] => (item=gdha) ok: [n4] => (item=gdha) ok: [n5] => (item=gdha) ok: [n1] => (item=ubuntu) ok: [n2] => (item=ubuntu) ok: [n3] => (item=ubuntu) ok: [n4] => (item=ubuntu) ok: [n5] => (item=ubuntu) TASK [ssh : Check if ssh key exists] *********************************************************************************************************** ok: [n1] ok: [n2] ok: [n3] ok: [n4] ok: [n5] TASK [ssh : Create .ssh directory] ************************************************************************************************************* ok: [n1] ok: [n2] ok: [n3] ok: [n4] ok: [n5] TASK [ssh : Generate ssh key] ****************************************************************************************************************** skipping: [n5] changed: [n1] changed: [n3] changed: [n2] changed: [n4] TASK [ssh : Slurp public keys from all nodes] ************************************************************************************************** ok: [n1] ok: [n3] ok: [n2] ok: [n4] ok: [n5] TASK [ssh : Copy public keys of all nodes into authorized_keys] ******************************************************************************** skipping: [n1] => (item=n1) skipping: [n1] => (item=n2) skipping: [n1] => (item=n3) skipping: [n1] => (item=n4) skipping: [n1] => (item=n5) skipping: [n2] => (item=n1) skipping: [n2] => (item=n2) skipping: [n2] => (item=n3) skipping: [n2] => (item=n4) skipping: [n2] => (item=n5) skipping: [n3] => (item=n1) skipping: [n3] => (item=n2) skipping: [n3] => (item=n3) skipping: [n3] => (item=n4) skipping: [n3] => (item=n5) skipping: [n4] => (item=n1) skipping: [n4] => (item=n2) skipping: [n4] => (item=n3) skipping: [n4] => (item=n4) skipping: [n4] => (item=n5) skipping: [n5] => (item=n1) skipping: [n5] => (item=n2) skipping: [n5] => (item=n3) skipping: [n5] => (item=n4) skipping: [n5] => (item=n5) TASK [ssh : Copy local public key to authorized_keys] ****************************************************************************************** ok: [n1] ok: [n2] ok: [n3] ok: [n4] ok: [n5] TASK [ssh : Slurp host keys from all nodes] **************************************************************************************************** ok: [n1] ok: [n2] ok: [n3] ok: [n4] ok: [n5] TASK [ssh : Insert all nodes into global known_hosts] ****************************************************************************************** ok: [n1] => (item=n1) ok: [n2] => (item=n1) ok: [n3] => (item=n1) ok: [n4] => (item=n1) ok: [n5] => (item=n1) ok: [n2] => (item=n2) ok: [n3] => (item=n2) ok: [n1] => (item=n2) ok: [n4] => (item=n2) ok: [n5] => (item=n2) ok: [n2] => (item=n3) ok: [n3] => (item=n3) ok: [n4] => (item=n3) ok: [n1] => (item=n3) ok: [n5] => (item=n3) ok: [n2] => (item=n4) ok: [n3] => (item=n4) ok: [n4] => (item=n4) ok: [n1] => (item=n4) ok: [n5] => (item=n4) ok: [n2] => (item=n5) ok: [n3] => (item=n5) ok: [n4] => (item=n5) ok: [n1] => (item=n5) ok: [n5] => (item=n5) TASK [ssh : Secure SSH configuration] ********************************************************************************************************** ok: [n1] => (item={'regexp': '^[# \\\\t]*Port', 'line': 'Port 22'}) ok: [n2] => (item={'regexp': '^[# \\\\t]*Port', 'line': 'Port 22'}) ok: [n3] => (item={'regexp': '^[# \\\\t]*Port', 'line': 'Port 22'}) ok: [n4] => (item={'regexp': '^[# \\\\t]*Port', 'line': 'Port 22'}) ok: [n5] => (item={'regexp': '^[# \\\\t]*Port', 'line': 'Port 22'}) ok: [n1] => (item={'regexp': '^[# \\\\t]*PasswordAuthentication', 'line': 'PasswordAuthentication yes'}) ok: [n2] => (item={'regexp': '^[# \\\\t]*PasswordAuthentication', 'line': 'PasswordAuthentication yes'}) ok: [n3] => (item={'regexp': '^[# \\\\t]*PasswordAuthentication', 'line': 'PasswordAuthentication yes'}) ok: [n4] => (item={'regexp': '^[# \\\\t]*PasswordAuthentication', 'line': 'PasswordAuthentication yes'}) ok: [n5] => (item={'regexp': '^[# \\\\t]*PasswordAuthentication', 'line': 'PasswordAuthentication yes'}) ok: [n1] => (item={'regexp': '^[# \\\\t]*PermitRootLogin', 'line': 'PermitRootLogin no'}) ok: [n2] => (item={'regexp': '^[# \\\\t]*PermitRootLogin', 'line': 'PermitRootLogin no'}) ok: [n3] => (item={'regexp': '^[# \\\\t]*PermitRootLogin', 'line': 'PermitRootLogin no'}) ok: [n4] => (item={'regexp': '^[# \\\\t]*PermitRootLogin', 'line': 'PermitRootLogin no'}) ok: [n5] => (item={'regexp': '^[# \\\\t]*PermitRootLogin', 'line': 'PermitRootLogin no'}) ok: [n1] => (item={'regexp': '^[# \\\\t]*UseDNS', 'line': 'UseDNS no'}) ok: [n2] => (item={'regexp': '^[# \\\\t]*UseDNS', 'line': 'UseDNS no'}) ok: [n3] => (item={'regexp': '^[# \\\\t]*UseDNS', 'line': 'UseDNS no'}) ok: [n4] => (item={'regexp': '^[# \\\\t]*UseDNS', 'line': 'UseDNS no'}) ok: [n5] => (item={'regexp': '^[# \\\\t]*UseDNS', 'line': 'UseDNS no'}) ok: [n1] => (item={'regexp': '^[# \\\\t]*PermitEmptyPasswords', 'line': 'PermitEmptyPasswords no'}) ok: [n2] => (item={'regexp': '^[# \\\\t]*PermitEmptyPasswords', 'line': 'PermitEmptyPasswords no'}) ok: [n3] => (item={'regexp': '^[# \\\\t]*PermitEmptyPasswords', 'line': 'PermitEmptyPasswords no'}) ok: [n4] => (item={'regexp': '^[# \\\\t]*PermitEmptyPasswords', 'line': 'PermitEmptyPasswords no'}) ok: [n1] => (item={'regexp': '^[# \\\\t]*ChallengeResponseAuthentication', 'line': 'ChallengeResponseAuthentication no'}) ok: [n5] => (item={'regexp': '^[# \\\\t]*PermitEmptyPasswords', 'line': 'PermitEmptyPasswords no'}) ok: [n2] => (item={'regexp': '^[# \\\\t]*ChallengeResponseAuthentication', 'line': 'ChallengeResponseAuthentication no'}) ok: [n3] => (item={'regexp': '^[# \\\\t]*ChallengeResponseAuthentication', 'line': 'ChallengeResponseAuthentication no'}) ok: [n4] => (item={'regexp': '^[# \\\\t]*ChallengeResponseAuthentication', 'line': 'ChallengeResponseAuthentication no'}) ok: [n1] => (item={'regexp': '^[# \\\\t]*GSSAPIAuthentication', 'line': 'GSSAPIAuthentication no'}) ok: [n2] => (item={'regexp': '^[# \\\\t]*GSSAPIAuthentication', 'line': 'GSSAPIAuthentication no'}) ok: [n5] => (item={'regexp': '^[# \\\\t]*ChallengeResponseAuthentication', 'line': 'ChallengeResponseAuthentication no'}) ok: [n3] => (item={'regexp': '^[# \\\\t]*GSSAPIAuthentication', 'line': 'GSSAPIAuthentication no'}) ok: [n4] => (item={'regexp': '^[# \\\\t]*GSSAPIAuthentication', 'line': 'GSSAPIAuthentication no'}) ok: [n1] => (item={'regexp': '^[# \\\\t]*X11Forwarding', 'line': 'X11Forwarding no'}) ok: [n2] => (item={'regexp': '^[# \\\\t]*X11Forwarding', 'line': 'X11Forwarding no'}) ok: [n5] => (item={'regexp': '^[# \\\\t]*GSSAPIAuthentication', 'line': 'GSSAPIAuthentication no'}) ok: [n3] => (item={'regexp': '^[# \\\\t]*X11Forwarding', 'line': 'X11Forwarding no'}) ok: [n4] => (item={'regexp': '^[# \\\\t]*X11Forwarding', 'line': 'X11Forwarding no'}) ok: [n5] => (item={'regexp': '^[# \\\\t]*X11Forwarding', 'line': 'X11Forwarding no'}) TASK [ssh : Secure SSH hosts configuration] **************************************************************************************************** ok: [n1] => (item={'regexp': '^[# \\\\t]*HashKnownHosts', 'line': 'HashKnownHosts no'}) ok: [n2] => (item={'regexp': '^[# \\\\t]*HashKnownHosts', 'line': 'HashKnownHosts no'}) ok: [n3] => (item={'regexp': '^[# \\\\t]*HashKnownHosts', 'line': 'HashKnownHosts no'}) ok: [n4] => (item={'regexp': '^[# \\\\t]*HashKnownHosts', 'line': 'HashKnownHosts no'}) ok: [n5] => (item={'regexp': '^[# \\\\t]*HashKnownHosts', 'line': 'HashKnownHosts no'}) PLAY RECAP ************************************************************************************************************************************* n1 : ok=38 changed=8 unreachable=0 failed=0 skipped=1 rescued=0 ignored=0 n2 : ok=38 changed=8 unreachable=0 failed=0 skipped=1 rescued=0 ignored=0 n3 : ok=38 changed=8 unreachable=0 failed=0 skipped=1 rescued=0 ignored=0 n4 : ok=38 changed=8 unreachable=0 failed=0 skipped=1 rescued=0 ignored=0 n5 : ok=37 changed=5 unreachable=0 failed=0 skipped=2 rescued=0 ignored=0 References \u00b6 [1] Ansible pi4-cluster-ansible-roles playbook [2] Source code for ARM side libraries for interfacing to Raspberry Pi GPU Edit history \u00b6 initial post on 09/Sep/2020","title":"Raspberry Pi 4 Prepare for kubernetes"},{"location":"pi-stories2/#pi4_stories","text":"","title":"PI4 Stories"},{"location":"pi-stories2/#raspberry_pi_4_cluster_series_-_prepare_for_kubernetes_installation","text":"","title":"Raspberry Pi 4 cluster Series - Prepare for kubernetes installation"},{"location":"pi-stories2/#add_account_with_secure_shell_keys_and_common_software_packages","text":"It is important that my account is created on each host with the requires secure shell keys. Also, we install what we think are required software packages on each host: vim git rsync acl dnsutils dphys-swapfile python-is-python3 sshpass ca-certificates curl gnupg-agent software-properties-common jq To get going first install git on the system where you start ansible playbooks (in our case it is host n5) and afterwards, clone the playbook pi4-cluster-ansible-roles . Do check the inventory.yml file and add you preferences. The playbook will also disable swap on each host, which is a requirement for kubernetes.","title":"Add account with Secure Shell keys and common software packages"},{"location":"pi-stories2/#compile_arm_side_libraries_for_interfacing_to_raspberry_pi_gpu","text":"Download the source code from 2 . Compile and install these binaries on the host from where you will use the playbook. In my case its was host n5 (do not forget to install ansible ).","title":"Compile ARM side libraries for interfacing to Raspberry Pi GPU"},{"location":"pi-stories2/#run_the_ansible_playbook_provisionyml","text":"$ ansible-playbook provision.yml -k --vault-password-file .my_password SSH password: PLAY [all] ************************************************************************************************************************************* TASK [Gathering Facts] ************************************************************************************************************************* ok: [n5] ok: [n3] ok: [n2] ok: [n4] ok: [n1] TASK [user : debug] **************************************************************************************************************************** ok: [n1] => { \"msg\": \"creating user gdha and OpenSSH public key distribution\" } ok: [n2] => { \"msg\": \"creating user gdha and OpenSSH public key distribution\" } ok: [n3] => { \"msg\": \"creating user gdha and OpenSSH public key distribution\" } ok: [n4] => { \"msg\": \"creating user gdha and OpenSSH public key distribution\" } ok: [n5] => { \"msg\": \"creating user gdha and OpenSSH public key distribution\" } TASK [user : Creating admin group] ************************************************************************************************************* ok: [n3] ok: [n1] ok: [n4] ok: [n2] ok: [n5] TASK [user : Add group gdha (1001)] ************************************************************************************************************ ok: [n1] ok: [n2] ok: [n3] ok: [n4] ok: [n5] TASK [user : Add user 'gdha' with specific uid (1001) and group 'gdha' (1001) and secondary group 'admin'] ************************************* ok: [n5] ok: [n2] ok: [n3] ok: [n1] ok: [n4] TASK [user : Create the /home/gdha/.ssh directory] ********************************************************************************************* ok: [n2] ok: [n1] ok: [n3] ok: [n4] ok: [n5] TASK [user : Copy /home/gdha/.ssh/id_rsa.pub to remote nodes] ********************************************************************************** ok: [n2] ok: [n3] ok: [n1] ok: [n4] ok: [n5] TASK [user : Append public ssh key of gdha to authorized_keys] ********************************************************************************* changed: [n1] => (item=/home/gdha/.ssh/id_rsa.pub) changed: [n4] => (item=/home/gdha/.ssh/id_rsa.pub) changed: [n2] => (item=/home/gdha/.ssh/id_rsa.pub) changed: [n3] => (item=/home/gdha/.ssh/id_rsa.pub) ok: [n5] => (item=/home/gdha/.ssh/id_rsa.pub) TASK [user : Create /etc/sudoers.d/gdha-sudoers file] ****************************************************************************************** ok: [n1] ok: [n2] ok: [n3] ok: [n4] ok: [n5] TASK [base : Set /etc/hosts for other nodes] *************************************************************************************************** ok: [n1] => (item=n2) ok: [n2] => (item=n1) ok: [n3] => (item=n1) ok: [n4] => (item=n1) ok: [n5] => (item=n1) ok: [n1] => (item=n3) ok: [n2] => (item=n3) ok: [n3] => (item=n2) ok: [n4] => (item=n2) ok: [n5] => (item=n2) ok: [n1] => (item=n4) ok: [n2] => (item=n4) ok: [n4] => (item=n3) ok: [n3] => (item=n4) ok: [n5] => (item=n3) ok: [n1] => (item=n5) ok: [n2] => (item=n5) ok: [n4] => (item=n5) ok: [n3] => (item=n5) ok: [n5] => (item=n4) TASK [base : Install common packages] ********************************************************************************************************** ok: [n5] changed: [n2] changed: [n3] changed: [n4] changed: [n1] TASK [base : Set default locale] *************************************************************************************************************** ok: [n1] ok: [n2] ok: [n3] ok: [n4] ok: [n5] TASK [base : Enable locale] ******************************************************************************************************************** ok: [n2] ok: [n1] ok: [n3] ok: [n4] ok: [n5] TASK [rpi : Create directory /opt/vc/bin] ****************************************************************************************************** ok: [n1] ok: [n2] ok: [n3] ok: [n4] ok: [n5] TASK [rpi : copy tvservice to /opt/vc/bin] ***************************************************************************************************** ok: [n1] ok: [n2] ok: [n3] ok: [n4] ok: [n5] TASK [rpi : Create the /opt/vc/lib directory] ************************************************************************************************** ok: [n1] ok: [n2] ok: [n3] ok: [n4] ok: [n5] TASK [rpi : Copy /opt/vc/lib/libvchiq_arm.so] ************************************************************************************************** ok: [n1] ok: [n2] ok: [n3] ok: [n4] ok: [n5] TASK [rpi : Copy /opt/vc/lib/libvcos.so] ******************************************************************************************************* ok: [n1] ok: [n2] ok: [n3] ok: [n4] ok: [n5] TASK [rpi : add /opt/vc/lib to /etc/ld.so.conf file] ******************************************************************************************* ok: [n1] ok: [n2] ok: [n3] ok: [n4] ok: [n5] TASK [rpi : Run ldconfig] ********************************************************************************************************************** changed: [n2] changed: [n1] changed: [n3] changed: [n4] changed: [n5] TASK [rpi : Check if HDMI is on] *************************************************************************************************************** ok: [n1] ok: [n2] ok: [n3] ok: [n4] ok: [n5] TASK [rpi : Switch off HDMI] ******************************************************************************************************************* changed: [n1] changed: [n2] changed: [n3] changed: [n4] changed: [n5] TASK [rpi : Ensure rc.local exists] ************************************************************************************************************ changed: [n1] changed: [n2] changed: [n3] changed: [n4] changed: [n5] TASK [rpi : Switch off HDMI on boot] *********************************************************************************************************** ok: [n1] ok: [n2] ok: [n3] ok: [n4] ok: [n5] TASK [os : Set hostname] *********************************************************************************************************************** ok: [n2] ok: [n3] ok: [n1] ok: [n4] ok: [n5] TASK [os : Set /etc/hosts hostname] ************************************************************************************************************ ok: [n1] ok: [n2] ok: [n3] ok: [n4] ok: [n5] TASK [os : Check if swap is enabled] *********************************************************************************************************** changed: [n1] changed: [n2] changed: [n3] changed: [n4] changed: [n5] TASK [os : Disable swap] *********************************************************************************************************************** changed: [n1] => (item=dphys-swapfile swapoff) changed: [n2] => (item=dphys-swapfile swapoff) changed: [n3] => (item=dphys-swapfile swapoff) changed: [n4] => (item=dphys-swapfile swapoff) changed: [n5] => (item=dphys-swapfile swapoff) changed: [n1] => (item=dphys-swapfile uninstall) changed: [n2] => (item=dphys-swapfile uninstall) changed: [n3] => (item=dphys-swapfile uninstall) changed: [n4] => (item=dphys-swapfile uninstall) changed: [n5] => (item=dphys-swapfile uninstall) changed: [n2] => (item=update-rc.d dphys-swapfile disable) changed: [n3] => (item=update-rc.d dphys-swapfile disable) changed: [n1] => (item=update-rc.d dphys-swapfile disable) changed: [n4] => (item=update-rc.d dphys-swapfile disable) changed: [n5] => (item=update-rc.d dphys-swapfile disable) TASK [os : Add users to passwordless sudoers.] ************************************************************************************************* ok: [n1] => (item=gdha) ok: [n2] => (item=gdha) ok: [n3] => (item=gdha) ok: [n4] => (item=gdha) ok: [n5] => (item=gdha) ok: [n1] => (item=ubuntu) ok: [n2] => (item=ubuntu) ok: [n3] => (item=ubuntu) ok: [n4] => (item=ubuntu) ok: [n5] => (item=ubuntu) TASK [ssh : Check if ssh key exists] *********************************************************************************************************** ok: [n1] ok: [n2] ok: [n3] ok: [n4] ok: [n5] TASK [ssh : Create .ssh directory] ************************************************************************************************************* ok: [n1] ok: [n2] ok: [n3] ok: [n4] ok: [n5] TASK [ssh : Generate ssh key] ****************************************************************************************************************** skipping: [n5] changed: [n1] changed: [n3] changed: [n2] changed: [n4] TASK [ssh : Slurp public keys from all nodes] ************************************************************************************************** ok: [n1] ok: [n3] ok: [n2] ok: [n4] ok: [n5] TASK [ssh : Copy public keys of all nodes into authorized_keys] ******************************************************************************** skipping: [n1] => (item=n1) skipping: [n1] => (item=n2) skipping: [n1] => (item=n3) skipping: [n1] => (item=n4) skipping: [n1] => (item=n5) skipping: [n2] => (item=n1) skipping: [n2] => (item=n2) skipping: [n2] => (item=n3) skipping: [n2] => (item=n4) skipping: [n2] => (item=n5) skipping: [n3] => (item=n1) skipping: [n3] => (item=n2) skipping: [n3] => (item=n3) skipping: [n3] => (item=n4) skipping: [n3] => (item=n5) skipping: [n4] => (item=n1) skipping: [n4] => (item=n2) skipping: [n4] => (item=n3) skipping: [n4] => (item=n4) skipping: [n4] => (item=n5) skipping: [n5] => (item=n1) skipping: [n5] => (item=n2) skipping: [n5] => (item=n3) skipping: [n5] => (item=n4) skipping: [n5] => (item=n5) TASK [ssh : Copy local public key to authorized_keys] ****************************************************************************************** ok: [n1] ok: [n2] ok: [n3] ok: [n4] ok: [n5] TASK [ssh : Slurp host keys from all nodes] **************************************************************************************************** ok: [n1] ok: [n2] ok: [n3] ok: [n4] ok: [n5] TASK [ssh : Insert all nodes into global known_hosts] ****************************************************************************************** ok: [n1] => (item=n1) ok: [n2] => (item=n1) ok: [n3] => (item=n1) ok: [n4] => (item=n1) ok: [n5] => (item=n1) ok: [n2] => (item=n2) ok: [n3] => (item=n2) ok: [n1] => (item=n2) ok: [n4] => (item=n2) ok: [n5] => (item=n2) ok: [n2] => (item=n3) ok: [n3] => (item=n3) ok: [n4] => (item=n3) ok: [n1] => (item=n3) ok: [n5] => (item=n3) ok: [n2] => (item=n4) ok: [n3] => (item=n4) ok: [n4] => (item=n4) ok: [n1] => (item=n4) ok: [n5] => (item=n4) ok: [n2] => (item=n5) ok: [n3] => (item=n5) ok: [n4] => (item=n5) ok: [n1] => (item=n5) ok: [n5] => (item=n5) TASK [ssh : Secure SSH configuration] ********************************************************************************************************** ok: [n1] => (item={'regexp': '^[# \\\\t]*Port', 'line': 'Port 22'}) ok: [n2] => (item={'regexp': '^[# \\\\t]*Port', 'line': 'Port 22'}) ok: [n3] => (item={'regexp': '^[# \\\\t]*Port', 'line': 'Port 22'}) ok: [n4] => (item={'regexp': '^[# \\\\t]*Port', 'line': 'Port 22'}) ok: [n5] => (item={'regexp': '^[# \\\\t]*Port', 'line': 'Port 22'}) ok: [n1] => (item={'regexp': '^[# \\\\t]*PasswordAuthentication', 'line': 'PasswordAuthentication yes'}) ok: [n2] => (item={'regexp': '^[# \\\\t]*PasswordAuthentication', 'line': 'PasswordAuthentication yes'}) ok: [n3] => (item={'regexp': '^[# \\\\t]*PasswordAuthentication', 'line': 'PasswordAuthentication yes'}) ok: [n4] => (item={'regexp': '^[# \\\\t]*PasswordAuthentication', 'line': 'PasswordAuthentication yes'}) ok: [n5] => (item={'regexp': '^[# \\\\t]*PasswordAuthentication', 'line': 'PasswordAuthentication yes'}) ok: [n1] => (item={'regexp': '^[# \\\\t]*PermitRootLogin', 'line': 'PermitRootLogin no'}) ok: [n2] => (item={'regexp': '^[# \\\\t]*PermitRootLogin', 'line': 'PermitRootLogin no'}) ok: [n3] => (item={'regexp': '^[# \\\\t]*PermitRootLogin', 'line': 'PermitRootLogin no'}) ok: [n4] => (item={'regexp': '^[# \\\\t]*PermitRootLogin', 'line': 'PermitRootLogin no'}) ok: [n5] => (item={'regexp': '^[# \\\\t]*PermitRootLogin', 'line': 'PermitRootLogin no'}) ok: [n1] => (item={'regexp': '^[# \\\\t]*UseDNS', 'line': 'UseDNS no'}) ok: [n2] => (item={'regexp': '^[# \\\\t]*UseDNS', 'line': 'UseDNS no'}) ok: [n3] => (item={'regexp': '^[# \\\\t]*UseDNS', 'line': 'UseDNS no'}) ok: [n4] => (item={'regexp': '^[# \\\\t]*UseDNS', 'line': 'UseDNS no'}) ok: [n5] => (item={'regexp': '^[# \\\\t]*UseDNS', 'line': 'UseDNS no'}) ok: [n1] => (item={'regexp': '^[# \\\\t]*PermitEmptyPasswords', 'line': 'PermitEmptyPasswords no'}) ok: [n2] => (item={'regexp': '^[# \\\\t]*PermitEmptyPasswords', 'line': 'PermitEmptyPasswords no'}) ok: [n3] => (item={'regexp': '^[# \\\\t]*PermitEmptyPasswords', 'line': 'PermitEmptyPasswords no'}) ok: [n4] => (item={'regexp': '^[# \\\\t]*PermitEmptyPasswords', 'line': 'PermitEmptyPasswords no'}) ok: [n1] => (item={'regexp': '^[# \\\\t]*ChallengeResponseAuthentication', 'line': 'ChallengeResponseAuthentication no'}) ok: [n5] => (item={'regexp': '^[# \\\\t]*PermitEmptyPasswords', 'line': 'PermitEmptyPasswords no'}) ok: [n2] => (item={'regexp': '^[# \\\\t]*ChallengeResponseAuthentication', 'line': 'ChallengeResponseAuthentication no'}) ok: [n3] => (item={'regexp': '^[# \\\\t]*ChallengeResponseAuthentication', 'line': 'ChallengeResponseAuthentication no'}) ok: [n4] => (item={'regexp': '^[# \\\\t]*ChallengeResponseAuthentication', 'line': 'ChallengeResponseAuthentication no'}) ok: [n1] => (item={'regexp': '^[# \\\\t]*GSSAPIAuthentication', 'line': 'GSSAPIAuthentication no'}) ok: [n2] => (item={'regexp': '^[# \\\\t]*GSSAPIAuthentication', 'line': 'GSSAPIAuthentication no'}) ok: [n5] => (item={'regexp': '^[# \\\\t]*ChallengeResponseAuthentication', 'line': 'ChallengeResponseAuthentication no'}) ok: [n3] => (item={'regexp': '^[# \\\\t]*GSSAPIAuthentication', 'line': 'GSSAPIAuthentication no'}) ok: [n4] => (item={'regexp': '^[# \\\\t]*GSSAPIAuthentication', 'line': 'GSSAPIAuthentication no'}) ok: [n1] => (item={'regexp': '^[# \\\\t]*X11Forwarding', 'line': 'X11Forwarding no'}) ok: [n2] => (item={'regexp': '^[# \\\\t]*X11Forwarding', 'line': 'X11Forwarding no'}) ok: [n5] => (item={'regexp': '^[# \\\\t]*GSSAPIAuthentication', 'line': 'GSSAPIAuthentication no'}) ok: [n3] => (item={'regexp': '^[# \\\\t]*X11Forwarding', 'line': 'X11Forwarding no'}) ok: [n4] => (item={'regexp': '^[# \\\\t]*X11Forwarding', 'line': 'X11Forwarding no'}) ok: [n5] => (item={'regexp': '^[# \\\\t]*X11Forwarding', 'line': 'X11Forwarding no'}) TASK [ssh : Secure SSH hosts configuration] **************************************************************************************************** ok: [n1] => (item={'regexp': '^[# \\\\t]*HashKnownHosts', 'line': 'HashKnownHosts no'}) ok: [n2] => (item={'regexp': '^[# \\\\t]*HashKnownHosts', 'line': 'HashKnownHosts no'}) ok: [n3] => (item={'regexp': '^[# \\\\t]*HashKnownHosts', 'line': 'HashKnownHosts no'}) ok: [n4] => (item={'regexp': '^[# \\\\t]*HashKnownHosts', 'line': 'HashKnownHosts no'}) ok: [n5] => (item={'regexp': '^[# \\\\t]*HashKnownHosts', 'line': 'HashKnownHosts no'}) PLAY RECAP ************************************************************************************************************************************* n1 : ok=38 changed=8 unreachable=0 failed=0 skipped=1 rescued=0 ignored=0 n2 : ok=38 changed=8 unreachable=0 failed=0 skipped=1 rescued=0 ignored=0 n3 : ok=38 changed=8 unreachable=0 failed=0 skipped=1 rescued=0 ignored=0 n4 : ok=38 changed=8 unreachable=0 failed=0 skipped=1 rescued=0 ignored=0 n5 : ok=37 changed=5 unreachable=0 failed=0 skipped=2 rescued=0 ignored=0","title":"Run the ansible playbook provision.yml"},{"location":"pi-stories2/#references","text":"[1] Ansible pi4-cluster-ansible-roles playbook [2] Source code for ARM side libraries for interfacing to Raspberry Pi GPU","title":"References"},{"location":"pi-stories2/#edit_history","text":"initial post on 09/Sep/2020","title":"Edit history"},{"location":"pi-stories3/","text":"PI4 Stories \u00b6 Raspberry Pi 4 cluster Series - Installing k3s software \u00b6 Why k3s? \u00b6 K3s is a fully compliant Kubernetes distribution in a single binary perfectly suitable for smaller edge devices such as the Raspberry PI4. Simply said, you can do almost exactly the same as with its big sister kubernetes (k8s). For these kind of devices it is the perfect match. To get ks3 installed with ansible clone the playbook k3s-ansible playbook [1]. K3s is a product from Rancher Labs and can be installed in different ways, such as with k3sup (read the nice article \" Deploying a highly-available K3s with K3sup \") or with a fork of k3s-ansible sources. We choose for the latter and made some customisation to fork of k3s-ansible playbook [1]. Do check the inventory/my-cluster/hosts.ini file and add you preferences. Also, do not forget to adjust the attributes yaml file inventory/my-cluster/group_vars/all.yml . Especially, check the k3s_version you want to install. To find the latest stable release of k3s see the github release page of ks3s . Run the ansible playbook site.yml \u00b6 gdha@n5:~/projects/k3s-ansible$ ansible-playbook site.yml -i inventory/my-cluster/hosts.ini [WARNING]: While constructing a mapping from /home/gdha/projects/k3s-ansible/roles/ubuntu/tasks/main.yml, line 4, column 5, found a duplicate dict key (backrefs). Using last defined value only. PLAY [k3s_cluster] ******************************************************************************************************************************************************** TASK [Gathering Facts] **************************************************************************************************************************************************** Wednesday 23 September 2020 16:16:13 +0200 (0:00:00.102) 0:00:00.102 *** ok: [192.168.0.202] ok: [192.168.0.204] ok: [192.168.0.203] ok: [192.168.0.201] ok: [192.168.0.205] TASK [prereq : Set SELinux to disabled state] ***************************************************************************************************************************** Wednesday 23 September 2020 16:16:24 +0200 (0:00:10.334) 0:00:10.437 *** skipping: [192.168.0.201] skipping: [192.168.0.202] skipping: [192.168.0.203] skipping: [192.168.0.204] skipping: [192.168.0.205] TASK [prereq : Enable IPv4 forwarding] ************************************************************************************************************************************ Wednesday 23 September 2020 16:16:24 +0200 (0:00:00.913) 0:00:11.350 *** ok: [192.168.0.203] ok: [192.168.0.201] ok: [192.168.0.202] ok: [192.168.0.204] ok: [192.168.0.205] TASK [prereq : Enable IPv6 forwarding] ************************************************************************************************************************************ Wednesday 23 September 2020 16:16:26 +0200 (0:00:01.658) 0:00:13.009 *** ok: [192.168.0.201] ok: [192.168.0.202] ok: [192.168.0.203] ok: [192.168.0.204] ok: [192.168.0.205] TASK [prereq : Add br_netfilter to /etc/modules-load.d/] ****************************************************************************************************************** Wednesday 23 September 2020 16:16:28 +0200 (0:00:01.781) 0:00:14.790 *** skipping: [192.168.0.201] skipping: [192.168.0.202] skipping: [192.168.0.203] skipping: [192.168.0.204] skipping: [192.168.0.205] TASK [prereq : Load br_netfilter] ***************************************************************************************************************************************** Wednesday 23 September 2020 16:16:29 +0200 (0:00:00.905) 0:00:15.696 *** skipping: [192.168.0.201] skipping: [192.168.0.202] skipping: [192.168.0.203] skipping: [192.168.0.204] skipping: [192.168.0.205] TASK [prereq : Set bridge-nf-call-iptables (just to be sure)] ************************************************************************************************************* Wednesday 23 September 2020 16:16:30 +0200 (0:00:00.909) 0:00:16.605 *** skipping: [192.168.0.201] => (item=net.bridge.bridge-nf-call-iptables) skipping: [192.168.0.201] => (item=net.bridge.bridge-nf-call-ip6tables) skipping: [192.168.0.202] => (item=net.bridge.bridge-nf-call-iptables) skipping: [192.168.0.202] => (item=net.bridge.bridge-nf-call-ip6tables) skipping: [192.168.0.203] => (item=net.bridge.bridge-nf-call-iptables) skipping: [192.168.0.203] => (item=net.bridge.bridge-nf-call-ip6tables) skipping: [192.168.0.204] => (item=net.bridge.bridge-nf-call-iptables) skipping: [192.168.0.204] => (item=net.bridge.bridge-nf-call-ip6tables) skipping: [192.168.0.205] => (item=net.bridge.bridge-nf-call-iptables) skipping: [192.168.0.205] => (item=net.bridge.bridge-nf-call-ip6tables) TASK [prereq : Add /usr/local/bin to sudo secure_path] ******************************************************************************************************************** Wednesday 23 September 2020 16:16:31 +0200 (0:00:00.939) 0:00:17.544 *** skipping: [192.168.0.201] skipping: [192.168.0.202] skipping: [192.168.0.203] skipping: [192.168.0.204] skipping: [192.168.0.205] TASK [download : Delete k3s if already present] *************************************************************************************************************************** Wednesday 23 September 2020 16:16:32 +0200 (0:00:01.169) 0:00:18.714 *** changed: [192.168.0.201] changed: [192.168.0.203] changed: [192.168.0.202] changed: [192.168.0.204] changed: [192.168.0.205] TASK [download : Download k3s binary x64] ********************************************************************************************************************************* Wednesday 23 September 2020 16:16:34 +0200 (0:00:01.707) 0:00:20.422 *** skipping: [192.168.0.201] skipping: [192.168.0.202] skipping: [192.168.0.203] skipping: [192.168.0.204] skipping: [192.168.0.205] TASK [download : Download k3s binary arm64] ******************************************************************************************************************************* Wednesday 23 September 2020 16:16:34 +0200 (0:00:00.943) 0:00:21.365 *** changed: [192.168.0.202] changed: [192.168.0.204] changed: [192.168.0.201] changed: [192.168.0.205] changed: [192.168.0.203] TASK [download : Download k3s binary armhf] ******************************************************************************************************************************* Wednesday 23 September 2020 16:17:34 +0200 (0:00:59.059) 0:01:20.425 *** skipping: [192.168.0.201] skipping: [192.168.0.202] skipping: [192.168.0.203] skipping: [192.168.0.204] skipping: [192.168.0.205] TASK [raspbian : Test for Raspbian] *************************************************************************************************************************************** Wednesday 23 September 2020 16:17:34 +0200 (0:00:00.940) 0:01:21.365 *** ok: [192.168.0.201] ok: [192.168.0.202] ok: [192.168.0.203] ok: [192.168.0.204] ok: [192.168.0.205] TASK [raspbian : Activating cgroup support] ******************************************************************************************************************************* Wednesday 23 September 2020 16:17:36 +0200 (0:00:01.165) 0:01:22.531 *** skipping: [192.168.0.201] skipping: [192.168.0.202] skipping: [192.168.0.203] skipping: [192.168.0.204] skipping: [192.168.0.205] TASK [raspbian : Flush iptables before changing to iptables-legacy] ******************************************************************************************************* Wednesday 23 September 2020 16:17:36 +0200 (0:00:00.796) 0:01:23.327 *** skipping: [192.168.0.201] skipping: [192.168.0.202] skipping: [192.168.0.203] skipping: [192.168.0.204] skipping: [192.168.0.205] TASK [raspbian : Changing to iptables-legacy] ***************************************************************************************************************************** Wednesday 23 September 2020 16:17:37 +0200 (0:00:00.795) 0:01:24.123 *** skipping: [192.168.0.201] skipping: [192.168.0.202] skipping: [192.168.0.203] skipping: [192.168.0.204] skipping: [192.168.0.205] TASK [raspbian : Changing to ip6tables-legacy] **************************************************************************************************************************** Wednesday 23 September 2020 16:17:38 +0200 (0:00:00.798) 0:01:24.922 *** skipping: [192.168.0.201] skipping: [192.168.0.202] skipping: [192.168.0.203] skipping: [192.168.0.204] skipping: [192.168.0.205] TASK [raspbian : Rebooting] *********************************************************************************************************************************************** Wednesday 23 September 2020 16:17:39 +0200 (0:00:00.940) 0:01:25.862 *** skipping: [192.168.0.201] skipping: [192.168.0.202] skipping: [192.168.0.203] skipping: [192.168.0.204] skipping: [192.168.0.205] TASK [ubuntu : Enable cgroup via boot commandline if not already enabled for Ubuntu on ARM] ******************************************************************************* Wednesday 23 September 2020 16:17:40 +0200 (0:00:00.800) 0:01:26.663 *** ok: [192.168.0.203] ok: [192.168.0.202] ok: [192.168.0.201] ok: [192.168.0.204] ok: [192.168.0.205] PLAY [master] ************************************************************************************************************************************************************* TASK [Gathering Facts] **************************************************************************************************************************************************** Wednesday 23 September 2020 16:17:42 +0200 (0:00:01.887) 0:01:28.550 *** ok: [192.168.0.201] TASK [k3s/master : Copy K3s service file] ********************************************************************************************************************************* Wednesday 23 September 2020 16:17:49 +0200 (0:00:07.512) 0:01:36.063 *** ok: [192.168.0.201] TASK [k3s/master : Enable and check K3s service] ************************************************************************************************************************** Wednesday 23 September 2020 16:17:51 +0200 (0:00:02.229) 0:01:38.293 *** changed: [192.168.0.201] TASK [k3s/master : Wait for node-token] *********************************************************************************************************************************** Wednesday 23 September 2020 16:18:11 +0200 (0:00:19.552) 0:01:57.846 *** ok: [192.168.0.201] TASK [k3s/master : Register node-token file access mode] ****************************************************************************************************************** Wednesday 23 September 2020 16:18:13 +0200 (0:00:01.661) 0:01:59.508 *** ok: [192.168.0.201] TASK [k3s/master : Change file access node-token] ************************************************************************************************************************* Wednesday 23 September 2020 16:18:14 +0200 (0:00:01.250) 0:02:00.758 *** changed: [192.168.0.201] TASK [k3s/master : Read node-token from master] *************************************************************************************************************************** Wednesday 23 September 2020 16:18:15 +0200 (0:00:01.036) 0:02:01.794 *** ok: [192.168.0.201] TASK [k3s/master : Store Master node-token] ******************************************************************************************************************************* Wednesday 23 September 2020 16:18:16 +0200 (0:00:01.293) 0:02:03.087 *** ok: [192.168.0.201] TASK [k3s/master : Restore node-token file access] ************************************************************************************************************************ Wednesday 23 September 2020 16:18:17 +0200 (0:00:00.277) 0:02:03.365 *** changed: [192.168.0.201] TASK [k3s/master : Create directory .kube] ******************************************************************************************************************************** Wednesday 23 September 2020 16:18:18 +0200 (0:00:01.079) 0:02:04.445 *** ok: [192.168.0.201] TASK [k3s/master : Copy config file to user home directory] *************************************************************************************************************** Wednesday 23 September 2020 16:18:19 +0200 (0:00:01.083) 0:02:05.528 *** changed: [192.168.0.201] TASK [k3s/master : Replace https://localhost:6443 by https://master-ip:6443] ********************************************************************************************** Wednesday 23 September 2020 16:18:20 +0200 (0:00:01.586) 0:02:07.115 *** changed: [192.168.0.201] TASK [k3s/master : Create kubectl symlink] ******************************************************************************************************************************** Wednesday 23 September 2020 16:18:22 +0200 (0:00:02.239) 0:02:09.354 *** ok: [192.168.0.201] TASK [k3s/master : Create crictl symlink] ********************************************************************************************************************************* Wednesday 23 September 2020 16:18:23 +0200 (0:00:00.973) 0:02:10.328 *** ok: [192.168.0.201] PLAY [node] *************************************************************************************************************************************************************** TASK [Gathering Facts] **************************************************************************************************************************************************** Wednesday 23 September 2020 16:18:25 +0200 (0:00:01.351) 0:02:11.680 *** ok: [192.168.0.203] ok: [192.168.0.205] ok: [192.168.0.202] ok: [192.168.0.204] TASK [k3s/node : Copy K3s service file] *********************************************************************************************************************************** Wednesday 23 September 2020 16:18:35 +0200 (0:00:09.865) 0:02:21.546 *** ok: [192.168.0.202] ok: [192.168.0.203] ok: [192.168.0.204] ok: [192.168.0.205] TASK [k3s/node : Enable and check K3s service] **************************************************************************************************************************** Wednesday 23 September 2020 16:18:37 +0200 (0:00:02.715) 0:02:24.261 *** changed: [192.168.0.202] changed: [192.168.0.204] changed: [192.168.0.205] changed: [192.168.0.203] TASK [k3s/node : Create directory .kube] ********************************************************************************************************************************** Wednesday 23 September 2020 16:18:46 +0200 (0:00:08.523) 0:02:32.785 *** ok: [192.168.0.202] ok: [192.168.0.203] ok: [192.168.0.204] ok: [192.168.0.205] TASK [k3s/node : Create kubectl/crictl symlinks] ************************************************************************************************************************** Wednesday 23 September 2020 16:18:48 +0200 (0:00:01.660) 0:02:34.446 *** ok: [192.168.0.202] => (item=kubectl) ok: [192.168.0.203] => (item=kubectl) ok: [192.168.0.204] => (item=kubectl) ok: [192.168.0.202] => (item=crictl) ok: [192.168.0.205] => (item=kubectl) ok: [192.168.0.203] => (item=crictl) ok: [192.168.0.204] => (item=crictl) ok: [192.168.0.205] => (item=crictl) TASK [k3s/node : fetch the ~/.kube/config file] *************************************************************************************************************************** Wednesday 23 September 2020 16:18:50 +0200 (0:00:02.746) 0:02:37.192 *** skipping: [192.168.0.202] skipping: [192.168.0.203] skipping: [192.168.0.204] skipping: [192.168.0.205] PLAY RECAP **************************************************************************************************************************************************************** 192.168.0.201 : ok=21 changed=7 unreachable=0 failed=0 skipped=12 rescued=0 ignored=0 192.168.0.202 : ok=12 changed=3 unreachable=0 failed=0 skipped=13 rescued=0 ignored=0 192.168.0.203 : ok=12 changed=3 unreachable=0 failed=0 skipped=13 rescued=0 ignored=0 192.168.0.204 : ok=12 changed=3 unreachable=0 failed=0 skipped=13 rescued=0 ignored=0 192.168.0.205 : ok=12 changed=3 unreachable=0 failed=0 skipped=13 rescued=0 ignored=0 Wednesday 23 September 2020 16:18:51 +0200 (0:00:00.630) 0:02:37.823 *** =============================================================================== download : Download k3s binary arm64 ------------------------------------------------------------------------------------------------------------------------------ 59.06s k3s/master : Enable and check K3s service ------------------------------------------------------------------------------------------------------------------------- 19.55s Gathering Facts --------------------------------------------------------------------------------------------------------------------------------------------------- 10.33s Gathering Facts ---------------------------------------------------------------------------------------------------------------------------------------------------- 9.87s k3s/node : Enable and check K3s service ---------------------------------------------------------------------------------------------------------------------------- 8.52s Gathering Facts ---------------------------------------------------------------------------------------------------------------------------------------------------- 7.51s k3s/node : Create kubectl/crictl symlinks -------------------------------------------------------------------------------------------------------------------------- 2.75s k3s/node : Copy K3s service file ----------------------------------------------------------------------------------------------------------------------------------- 2.72s k3s/master : Replace https://localhost:6443 by https://master-ip:6443 ---------------------------------------------------------------------------------------------- 2.24s k3s/master : Copy K3s service file --------------------------------------------------------------------------------------------------------------------------------- 2.23s ubuntu : Enable cgroup via boot commandline if not already enabled for Ubuntu on ARM ------------------------------------------------------------------------------- 1.89s prereq : Enable IPv6 forwarding ------------------------------------------------------------------------------------------------------------------------------------ 1.78s download : Delete k3s if already present --------------------------------------------------------------------------------------------------------------------------- 1.71s k3s/master : Wait for node-token ----------------------------------------------------------------------------------------------------------------------------------- 1.66s k3s/node : Create directory .kube ---------------------------------------------------------------------------------------------------------------------------------- 1.66s prereq : Enable IPv4 forwarding ------------------------------------------------------------------------------------------------------------------------------------ 1.66s k3s/master : Copy config file to user home directory --------------------------------------------------------------------------------------------------------------- 1.59s k3s/master : Create crictl symlink --------------------------------------------------------------------------------------------------------------------------------- 1.35s k3s/master : Read node-token from master --------------------------------------------------------------------------------------------------------------------------- 1.29s k3s/master : Register node-token file access mode ------------------------------------------------------------------------------------------------------------------ 1.25s k3s is up and running? \u00b6 Wow the installation went rather fast - an exciting moment - is k3s working fine? gdha@n5:~/projects/k3s-ansible$ k3s --version k3s version v1.19.2+k3s1 (d38505b1) gdha@n5:~/projects/k3s-ansible$ k3s kubectl cluster-info To further debug and diagnose cluster problems, use 'kubectl cluster-info dump'. The connection to the server localhost:8080 was refused - did you specify the right host or port? Ok - k3s needs the cluster configuration file via variable KUBECONFIG or the file ~/kube/config . We are on a worker node (n5) and choose as master node n1, therefore, the cluster configuration was created and resides on the master node. Or, we copy this to each node or decide only the work from the master node. It is a much better choice to copy the configuration to each node instead. To do so first copy the cluster configuration file from the master node (n1) to this node (n5): gdha@n5:~/projects/k3s-ansible$ scp n1:.kube/config ~/.kube/ config 100% 2793 2.0MB/s 00:00 Now see if we have more luck with a kubernetes command to get all the nodes in this cluster and dumping the cluster-info? gdha@n5:~/projects/k3s-ansible$ kubectl get nodes NAME STATUS ROLES AGE VERSION n2 Ready <none> 49d v1.19.2+k3s1 n5 Ready <none> 49d v1.19.2+k3s1 n4 Ready <none> 49d v1.19.2+k3s1 n3 Ready <none> 49d v1.19.2+k3s1 n1 Ready master 49d v1.19.2+k3s1 gdha@n5:~/projects/k3s-ansible$ k3s kubectl cluster-info Kubernetes master is running at https://192.168.0.201:6443 CoreDNS is running at https://192.168.0.201:6443/api/v1/namespaces/kube-system/services/kube-dns:dns/proxy Metrics-server is running at https://192.168.0.201:6443/api/v1/namespaces/kube-system/services/https:metrics-server:/proxy To further debug and diagnose cluster problems, use 'kubectl cluster-info dump'. Yes, that works fine, so lets copy the configuration file to the other nodes as well: gdha@n5:~/projects/k3s-ansible$ scp ~/.kube/config n2:~/.kube/ config 100% 2793 1.9MB/s 00:00 gdha@n5:~/projects/k3s-ansible$ scp ~/.kube/config n3:~/.kube/ config 100% 2793 1.7MB/s 00:00 gdha@n5:~/projects/k3s-ansible$ scp ~/.kube/config n4:~/.kube/ config And finally, to conclude this story, what pods are running within a basic k3s setup? gdha@n5:~/projects/k3s-ansible$ kubectl get pods -A NAMESPACE NAME READY STATUS RESTARTS AGE kube-system helm-install-traefik-p7jkh 0/1 Completed 0 4d22h kube-system svclb-traefik-kxxn4 2/2 Running 2 4d22h kube-system svclb-traefik-r9q6r 2/2 Running 2 4d22h kube-system svclb-traefik-qlgn9 2/2 Running 2 4d22h kube-system traefik-5dd496474-4fwdm 1/1 Running 1 4d22h kube-system local-path-provisioner-7ff9579c6-l6t6s 1/1 Running 1 4d22h kube-system svclb-traefik-n6srr 2/2 Running 2 4d22h kube-system coredns-66c464876b-vqrd6 1/1 Running 1 4d22h kube-system metrics-server-7b4f8b595-bldsd 1/1 Running 1 4d22h kube-system svclb-traefik-74k9f 2/2 Running 2 4d22h References \u00b6 [1] Ansible k3s-ansible playbook [2] Deploying a highly-available K3s with K3sup Edit history \u00b6 initial post on 28/Sep/2020","title":"Raspberry Pi 4 Installing k3s software"},{"location":"pi-stories3/#pi4_stories","text":"","title":"PI4 Stories"},{"location":"pi-stories3/#raspberry_pi_4_cluster_series_-_installing_k3s_software","text":"","title":"Raspberry Pi 4 cluster Series - Installing k3s software"},{"location":"pi-stories3/#why_k3s","text":"K3s is a fully compliant Kubernetes distribution in a single binary perfectly suitable for smaller edge devices such as the Raspberry PI4. Simply said, you can do almost exactly the same as with its big sister kubernetes (k8s). For these kind of devices it is the perfect match. To get ks3 installed with ansible clone the playbook k3s-ansible playbook [1]. K3s is a product from Rancher Labs and can be installed in different ways, such as with k3sup (read the nice article \" Deploying a highly-available K3s with K3sup \") or with a fork of k3s-ansible sources. We choose for the latter and made some customisation to fork of k3s-ansible playbook [1]. Do check the inventory/my-cluster/hosts.ini file and add you preferences. Also, do not forget to adjust the attributes yaml file inventory/my-cluster/group_vars/all.yml . Especially, check the k3s_version you want to install. To find the latest stable release of k3s see the github release page of ks3s .","title":"Why k3s?"},{"location":"pi-stories3/#run_the_ansible_playbook_siteyml","text":"gdha@n5:~/projects/k3s-ansible$ ansible-playbook site.yml -i inventory/my-cluster/hosts.ini [WARNING]: While constructing a mapping from /home/gdha/projects/k3s-ansible/roles/ubuntu/tasks/main.yml, line 4, column 5, found a duplicate dict key (backrefs). Using last defined value only. PLAY [k3s_cluster] ******************************************************************************************************************************************************** TASK [Gathering Facts] **************************************************************************************************************************************************** Wednesday 23 September 2020 16:16:13 +0200 (0:00:00.102) 0:00:00.102 *** ok: [192.168.0.202] ok: [192.168.0.204] ok: [192.168.0.203] ok: [192.168.0.201] ok: [192.168.0.205] TASK [prereq : Set SELinux to disabled state] ***************************************************************************************************************************** Wednesday 23 September 2020 16:16:24 +0200 (0:00:10.334) 0:00:10.437 *** skipping: [192.168.0.201] skipping: [192.168.0.202] skipping: [192.168.0.203] skipping: [192.168.0.204] skipping: [192.168.0.205] TASK [prereq : Enable IPv4 forwarding] ************************************************************************************************************************************ Wednesday 23 September 2020 16:16:24 +0200 (0:00:00.913) 0:00:11.350 *** ok: [192.168.0.203] ok: [192.168.0.201] ok: [192.168.0.202] ok: [192.168.0.204] ok: [192.168.0.205] TASK [prereq : Enable IPv6 forwarding] ************************************************************************************************************************************ Wednesday 23 September 2020 16:16:26 +0200 (0:00:01.658) 0:00:13.009 *** ok: [192.168.0.201] ok: [192.168.0.202] ok: [192.168.0.203] ok: [192.168.0.204] ok: [192.168.0.205] TASK [prereq : Add br_netfilter to /etc/modules-load.d/] ****************************************************************************************************************** Wednesday 23 September 2020 16:16:28 +0200 (0:00:01.781) 0:00:14.790 *** skipping: [192.168.0.201] skipping: [192.168.0.202] skipping: [192.168.0.203] skipping: [192.168.0.204] skipping: [192.168.0.205] TASK [prereq : Load br_netfilter] ***************************************************************************************************************************************** Wednesday 23 September 2020 16:16:29 +0200 (0:00:00.905) 0:00:15.696 *** skipping: [192.168.0.201] skipping: [192.168.0.202] skipping: [192.168.0.203] skipping: [192.168.0.204] skipping: [192.168.0.205] TASK [prereq : Set bridge-nf-call-iptables (just to be sure)] ************************************************************************************************************* Wednesday 23 September 2020 16:16:30 +0200 (0:00:00.909) 0:00:16.605 *** skipping: [192.168.0.201] => (item=net.bridge.bridge-nf-call-iptables) skipping: [192.168.0.201] => (item=net.bridge.bridge-nf-call-ip6tables) skipping: [192.168.0.202] => (item=net.bridge.bridge-nf-call-iptables) skipping: [192.168.0.202] => (item=net.bridge.bridge-nf-call-ip6tables) skipping: [192.168.0.203] => (item=net.bridge.bridge-nf-call-iptables) skipping: [192.168.0.203] => (item=net.bridge.bridge-nf-call-ip6tables) skipping: [192.168.0.204] => (item=net.bridge.bridge-nf-call-iptables) skipping: [192.168.0.204] => (item=net.bridge.bridge-nf-call-ip6tables) skipping: [192.168.0.205] => (item=net.bridge.bridge-nf-call-iptables) skipping: [192.168.0.205] => (item=net.bridge.bridge-nf-call-ip6tables) TASK [prereq : Add /usr/local/bin to sudo secure_path] ******************************************************************************************************************** Wednesday 23 September 2020 16:16:31 +0200 (0:00:00.939) 0:00:17.544 *** skipping: [192.168.0.201] skipping: [192.168.0.202] skipping: [192.168.0.203] skipping: [192.168.0.204] skipping: [192.168.0.205] TASK [download : Delete k3s if already present] *************************************************************************************************************************** Wednesday 23 September 2020 16:16:32 +0200 (0:00:01.169) 0:00:18.714 *** changed: [192.168.0.201] changed: [192.168.0.203] changed: [192.168.0.202] changed: [192.168.0.204] changed: [192.168.0.205] TASK [download : Download k3s binary x64] ********************************************************************************************************************************* Wednesday 23 September 2020 16:16:34 +0200 (0:00:01.707) 0:00:20.422 *** skipping: [192.168.0.201] skipping: [192.168.0.202] skipping: [192.168.0.203] skipping: [192.168.0.204] skipping: [192.168.0.205] TASK [download : Download k3s binary arm64] ******************************************************************************************************************************* Wednesday 23 September 2020 16:16:34 +0200 (0:00:00.943) 0:00:21.365 *** changed: [192.168.0.202] changed: [192.168.0.204] changed: [192.168.0.201] changed: [192.168.0.205] changed: [192.168.0.203] TASK [download : Download k3s binary armhf] ******************************************************************************************************************************* Wednesday 23 September 2020 16:17:34 +0200 (0:00:59.059) 0:01:20.425 *** skipping: [192.168.0.201] skipping: [192.168.0.202] skipping: [192.168.0.203] skipping: [192.168.0.204] skipping: [192.168.0.205] TASK [raspbian : Test for Raspbian] *************************************************************************************************************************************** Wednesday 23 September 2020 16:17:34 +0200 (0:00:00.940) 0:01:21.365 *** ok: [192.168.0.201] ok: [192.168.0.202] ok: [192.168.0.203] ok: [192.168.0.204] ok: [192.168.0.205] TASK [raspbian : Activating cgroup support] ******************************************************************************************************************************* Wednesday 23 September 2020 16:17:36 +0200 (0:00:01.165) 0:01:22.531 *** skipping: [192.168.0.201] skipping: [192.168.0.202] skipping: [192.168.0.203] skipping: [192.168.0.204] skipping: [192.168.0.205] TASK [raspbian : Flush iptables before changing to iptables-legacy] ******************************************************************************************************* Wednesday 23 September 2020 16:17:36 +0200 (0:00:00.796) 0:01:23.327 *** skipping: [192.168.0.201] skipping: [192.168.0.202] skipping: [192.168.0.203] skipping: [192.168.0.204] skipping: [192.168.0.205] TASK [raspbian : Changing to iptables-legacy] ***************************************************************************************************************************** Wednesday 23 September 2020 16:17:37 +0200 (0:00:00.795) 0:01:24.123 *** skipping: [192.168.0.201] skipping: [192.168.0.202] skipping: [192.168.0.203] skipping: [192.168.0.204] skipping: [192.168.0.205] TASK [raspbian : Changing to ip6tables-legacy] **************************************************************************************************************************** Wednesday 23 September 2020 16:17:38 +0200 (0:00:00.798) 0:01:24.922 *** skipping: [192.168.0.201] skipping: [192.168.0.202] skipping: [192.168.0.203] skipping: [192.168.0.204] skipping: [192.168.0.205] TASK [raspbian : Rebooting] *********************************************************************************************************************************************** Wednesday 23 September 2020 16:17:39 +0200 (0:00:00.940) 0:01:25.862 *** skipping: [192.168.0.201] skipping: [192.168.0.202] skipping: [192.168.0.203] skipping: [192.168.0.204] skipping: [192.168.0.205] TASK [ubuntu : Enable cgroup via boot commandline if not already enabled for Ubuntu on ARM] ******************************************************************************* Wednesday 23 September 2020 16:17:40 +0200 (0:00:00.800) 0:01:26.663 *** ok: [192.168.0.203] ok: [192.168.0.202] ok: [192.168.0.201] ok: [192.168.0.204] ok: [192.168.0.205] PLAY [master] ************************************************************************************************************************************************************* TASK [Gathering Facts] **************************************************************************************************************************************************** Wednesday 23 September 2020 16:17:42 +0200 (0:00:01.887) 0:01:28.550 *** ok: [192.168.0.201] TASK [k3s/master : Copy K3s service file] ********************************************************************************************************************************* Wednesday 23 September 2020 16:17:49 +0200 (0:00:07.512) 0:01:36.063 *** ok: [192.168.0.201] TASK [k3s/master : Enable and check K3s service] ************************************************************************************************************************** Wednesday 23 September 2020 16:17:51 +0200 (0:00:02.229) 0:01:38.293 *** changed: [192.168.0.201] TASK [k3s/master : Wait for node-token] *********************************************************************************************************************************** Wednesday 23 September 2020 16:18:11 +0200 (0:00:19.552) 0:01:57.846 *** ok: [192.168.0.201] TASK [k3s/master : Register node-token file access mode] ****************************************************************************************************************** Wednesday 23 September 2020 16:18:13 +0200 (0:00:01.661) 0:01:59.508 *** ok: [192.168.0.201] TASK [k3s/master : Change file access node-token] ************************************************************************************************************************* Wednesday 23 September 2020 16:18:14 +0200 (0:00:01.250) 0:02:00.758 *** changed: [192.168.0.201] TASK [k3s/master : Read node-token from master] *************************************************************************************************************************** Wednesday 23 September 2020 16:18:15 +0200 (0:00:01.036) 0:02:01.794 *** ok: [192.168.0.201] TASK [k3s/master : Store Master node-token] ******************************************************************************************************************************* Wednesday 23 September 2020 16:18:16 +0200 (0:00:01.293) 0:02:03.087 *** ok: [192.168.0.201] TASK [k3s/master : Restore node-token file access] ************************************************************************************************************************ Wednesday 23 September 2020 16:18:17 +0200 (0:00:00.277) 0:02:03.365 *** changed: [192.168.0.201] TASK [k3s/master : Create directory .kube] ******************************************************************************************************************************** Wednesday 23 September 2020 16:18:18 +0200 (0:00:01.079) 0:02:04.445 *** ok: [192.168.0.201] TASK [k3s/master : Copy config file to user home directory] *************************************************************************************************************** Wednesday 23 September 2020 16:18:19 +0200 (0:00:01.083) 0:02:05.528 *** changed: [192.168.0.201] TASK [k3s/master : Replace https://localhost:6443 by https://master-ip:6443] ********************************************************************************************** Wednesday 23 September 2020 16:18:20 +0200 (0:00:01.586) 0:02:07.115 *** changed: [192.168.0.201] TASK [k3s/master : Create kubectl symlink] ******************************************************************************************************************************** Wednesday 23 September 2020 16:18:22 +0200 (0:00:02.239) 0:02:09.354 *** ok: [192.168.0.201] TASK [k3s/master : Create crictl symlink] ********************************************************************************************************************************* Wednesday 23 September 2020 16:18:23 +0200 (0:00:00.973) 0:02:10.328 *** ok: [192.168.0.201] PLAY [node] *************************************************************************************************************************************************************** TASK [Gathering Facts] **************************************************************************************************************************************************** Wednesday 23 September 2020 16:18:25 +0200 (0:00:01.351) 0:02:11.680 *** ok: [192.168.0.203] ok: [192.168.0.205] ok: [192.168.0.202] ok: [192.168.0.204] TASK [k3s/node : Copy K3s service file] *********************************************************************************************************************************** Wednesday 23 September 2020 16:18:35 +0200 (0:00:09.865) 0:02:21.546 *** ok: [192.168.0.202] ok: [192.168.0.203] ok: [192.168.0.204] ok: [192.168.0.205] TASK [k3s/node : Enable and check K3s service] **************************************************************************************************************************** Wednesday 23 September 2020 16:18:37 +0200 (0:00:02.715) 0:02:24.261 *** changed: [192.168.0.202] changed: [192.168.0.204] changed: [192.168.0.205] changed: [192.168.0.203] TASK [k3s/node : Create directory .kube] ********************************************************************************************************************************** Wednesday 23 September 2020 16:18:46 +0200 (0:00:08.523) 0:02:32.785 *** ok: [192.168.0.202] ok: [192.168.0.203] ok: [192.168.0.204] ok: [192.168.0.205] TASK [k3s/node : Create kubectl/crictl symlinks] ************************************************************************************************************************** Wednesday 23 September 2020 16:18:48 +0200 (0:00:01.660) 0:02:34.446 *** ok: [192.168.0.202] => (item=kubectl) ok: [192.168.0.203] => (item=kubectl) ok: [192.168.0.204] => (item=kubectl) ok: [192.168.0.202] => (item=crictl) ok: [192.168.0.205] => (item=kubectl) ok: [192.168.0.203] => (item=crictl) ok: [192.168.0.204] => (item=crictl) ok: [192.168.0.205] => (item=crictl) TASK [k3s/node : fetch the ~/.kube/config file] *************************************************************************************************************************** Wednesday 23 September 2020 16:18:50 +0200 (0:00:02.746) 0:02:37.192 *** skipping: [192.168.0.202] skipping: [192.168.0.203] skipping: [192.168.0.204] skipping: [192.168.0.205] PLAY RECAP **************************************************************************************************************************************************************** 192.168.0.201 : ok=21 changed=7 unreachable=0 failed=0 skipped=12 rescued=0 ignored=0 192.168.0.202 : ok=12 changed=3 unreachable=0 failed=0 skipped=13 rescued=0 ignored=0 192.168.0.203 : ok=12 changed=3 unreachable=0 failed=0 skipped=13 rescued=0 ignored=0 192.168.0.204 : ok=12 changed=3 unreachable=0 failed=0 skipped=13 rescued=0 ignored=0 192.168.0.205 : ok=12 changed=3 unreachable=0 failed=0 skipped=13 rescued=0 ignored=0 Wednesday 23 September 2020 16:18:51 +0200 (0:00:00.630) 0:02:37.823 *** =============================================================================== download : Download k3s binary arm64 ------------------------------------------------------------------------------------------------------------------------------ 59.06s k3s/master : Enable and check K3s service ------------------------------------------------------------------------------------------------------------------------- 19.55s Gathering Facts --------------------------------------------------------------------------------------------------------------------------------------------------- 10.33s Gathering Facts ---------------------------------------------------------------------------------------------------------------------------------------------------- 9.87s k3s/node : Enable and check K3s service ---------------------------------------------------------------------------------------------------------------------------- 8.52s Gathering Facts ---------------------------------------------------------------------------------------------------------------------------------------------------- 7.51s k3s/node : Create kubectl/crictl symlinks -------------------------------------------------------------------------------------------------------------------------- 2.75s k3s/node : Copy K3s service file ----------------------------------------------------------------------------------------------------------------------------------- 2.72s k3s/master : Replace https://localhost:6443 by https://master-ip:6443 ---------------------------------------------------------------------------------------------- 2.24s k3s/master : Copy K3s service file --------------------------------------------------------------------------------------------------------------------------------- 2.23s ubuntu : Enable cgroup via boot commandline if not already enabled for Ubuntu on ARM ------------------------------------------------------------------------------- 1.89s prereq : Enable IPv6 forwarding ------------------------------------------------------------------------------------------------------------------------------------ 1.78s download : Delete k3s if already present --------------------------------------------------------------------------------------------------------------------------- 1.71s k3s/master : Wait for node-token ----------------------------------------------------------------------------------------------------------------------------------- 1.66s k3s/node : Create directory .kube ---------------------------------------------------------------------------------------------------------------------------------- 1.66s prereq : Enable IPv4 forwarding ------------------------------------------------------------------------------------------------------------------------------------ 1.66s k3s/master : Copy config file to user home directory --------------------------------------------------------------------------------------------------------------- 1.59s k3s/master : Create crictl symlink --------------------------------------------------------------------------------------------------------------------------------- 1.35s k3s/master : Read node-token from master --------------------------------------------------------------------------------------------------------------------------- 1.29s k3s/master : Register node-token file access mode ------------------------------------------------------------------------------------------------------------------ 1.25s","title":"Run the ansible playbook site.yml"},{"location":"pi-stories3/#k3s_is_up_and_running","text":"Wow the installation went rather fast - an exciting moment - is k3s working fine? gdha@n5:~/projects/k3s-ansible$ k3s --version k3s version v1.19.2+k3s1 (d38505b1) gdha@n5:~/projects/k3s-ansible$ k3s kubectl cluster-info To further debug and diagnose cluster problems, use 'kubectl cluster-info dump'. The connection to the server localhost:8080 was refused - did you specify the right host or port? Ok - k3s needs the cluster configuration file via variable KUBECONFIG or the file ~/kube/config . We are on a worker node (n5) and choose as master node n1, therefore, the cluster configuration was created and resides on the master node. Or, we copy this to each node or decide only the work from the master node. It is a much better choice to copy the configuration to each node instead. To do so first copy the cluster configuration file from the master node (n1) to this node (n5): gdha@n5:~/projects/k3s-ansible$ scp n1:.kube/config ~/.kube/ config 100% 2793 2.0MB/s 00:00 Now see if we have more luck with a kubernetes command to get all the nodes in this cluster and dumping the cluster-info? gdha@n5:~/projects/k3s-ansible$ kubectl get nodes NAME STATUS ROLES AGE VERSION n2 Ready <none> 49d v1.19.2+k3s1 n5 Ready <none> 49d v1.19.2+k3s1 n4 Ready <none> 49d v1.19.2+k3s1 n3 Ready <none> 49d v1.19.2+k3s1 n1 Ready master 49d v1.19.2+k3s1 gdha@n5:~/projects/k3s-ansible$ k3s kubectl cluster-info Kubernetes master is running at https://192.168.0.201:6443 CoreDNS is running at https://192.168.0.201:6443/api/v1/namespaces/kube-system/services/kube-dns:dns/proxy Metrics-server is running at https://192.168.0.201:6443/api/v1/namespaces/kube-system/services/https:metrics-server:/proxy To further debug and diagnose cluster problems, use 'kubectl cluster-info dump'. Yes, that works fine, so lets copy the configuration file to the other nodes as well: gdha@n5:~/projects/k3s-ansible$ scp ~/.kube/config n2:~/.kube/ config 100% 2793 1.9MB/s 00:00 gdha@n5:~/projects/k3s-ansible$ scp ~/.kube/config n3:~/.kube/ config 100% 2793 1.7MB/s 00:00 gdha@n5:~/projects/k3s-ansible$ scp ~/.kube/config n4:~/.kube/ config And finally, to conclude this story, what pods are running within a basic k3s setup? gdha@n5:~/projects/k3s-ansible$ kubectl get pods -A NAMESPACE NAME READY STATUS RESTARTS AGE kube-system helm-install-traefik-p7jkh 0/1 Completed 0 4d22h kube-system svclb-traefik-kxxn4 2/2 Running 2 4d22h kube-system svclb-traefik-r9q6r 2/2 Running 2 4d22h kube-system svclb-traefik-qlgn9 2/2 Running 2 4d22h kube-system traefik-5dd496474-4fwdm 1/1 Running 1 4d22h kube-system local-path-provisioner-7ff9579c6-l6t6s 1/1 Running 1 4d22h kube-system svclb-traefik-n6srr 2/2 Running 2 4d22h kube-system coredns-66c464876b-vqrd6 1/1 Running 1 4d22h kube-system metrics-server-7b4f8b595-bldsd 1/1 Running 1 4d22h kube-system svclb-traefik-74k9f 2/2 Running 2 4d22h","title":"k3s is up and running?"},{"location":"pi-stories3/#references","text":"[1] Ansible k3s-ansible playbook [2] Deploying a highly-available K3s with K3sup","title":"References"},{"location":"pi-stories3/#edit_history","text":"initial post on 28/Sep/2020","title":"Edit history"},{"location":"pi-stories4/","text":"PI4 Stories \u00b6 Raspberry Pi 4 cluster Series - Install awesome kubectl aliases \u00b6 The article \" Awesome Kubernetes Command-Line Hacks \" points out some interesting items to take in account. In summary activate the autocompletion and generate the kubectl aliases to make your life better. Enable kubectl autocompletion \u00b6 Enable kubectl autocompletion is one of the first things you have to do to make your life a bit easier. There are two ways in which you can do this: Source the completion script in your ~/.bashrc file: echo 'source <(kubectl completion bash)' >>~/.bashrc Add the completion script to the /etc/bash_completion.d directory: kubectl completion bash >/etc/bash_completion.d/kubectl If you have an alias for kubectl, you can extend shell completion to work with that alias: echo 'alias k=kubectl' >>~/.bashrc echo 'complete -F __start_kubectl k' >>~/.bashrc Above information come from kubernetes kubectl page . If you are alone then go for the first option, if more users require these autocompletion then go for the latter option. Kubectl aliases \u00b6 Kubectl commands can be long and hard to type over and over again, therefore, why not apply the kubectl-aliases github project . References \u00b6 [1] Awesome Kubernetes Command-Line Hacks [2] kubectl-aliases GitHub Source Edit history \u00b6 initial post on 30/Sep/2020","title":"Raspberry Pi 4 Install awesome kubectl aliases"},{"location":"pi-stories4/#pi4_stories","text":"","title":"PI4 Stories"},{"location":"pi-stories4/#raspberry_pi_4_cluster_series_-_install_awesome_kubectl_aliases","text":"The article \" Awesome Kubernetes Command-Line Hacks \" points out some interesting items to take in account. In summary activate the autocompletion and generate the kubectl aliases to make your life better.","title":"Raspberry Pi 4 cluster Series - Install awesome kubectl aliases"},{"location":"pi-stories4/#enable_kubectl_autocompletion","text":"Enable kubectl autocompletion is one of the first things you have to do to make your life a bit easier. There are two ways in which you can do this: Source the completion script in your ~/.bashrc file: echo 'source <(kubectl completion bash)' >>~/.bashrc Add the completion script to the /etc/bash_completion.d directory: kubectl completion bash >/etc/bash_completion.d/kubectl If you have an alias for kubectl, you can extend shell completion to work with that alias: echo 'alias k=kubectl' >>~/.bashrc echo 'complete -F __start_kubectl k' >>~/.bashrc Above information come from kubernetes kubectl page . If you are alone then go for the first option, if more users require these autocompletion then go for the latter option.","title":"Enable kubectl autocompletion"},{"location":"pi-stories4/#kubectl_aliases","text":"Kubectl commands can be long and hard to type over and over again, therefore, why not apply the kubectl-aliases github project .","title":"Kubectl aliases"},{"location":"pi-stories4/#references","text":"[1] Awesome Kubernetes Command-Line Hacks [2] kubectl-aliases GitHub Source","title":"References"},{"location":"pi-stories4/#edit_history","text":"initial post on 30/Sep/2020","title":"Edit history"},{"location":"pi-stories5/","text":"PI4 Stories \u00b6 Raspberry Pi 4 cluster Series - Installing cert-manager on the k3s cluster \u00b6 As certificates are crucial in a kuberbetes cluster one of the first pods that one should install is cert-manager . Installling cert-manager \u00b6 Installaion is extremelt easy with the following command: kubectl apply --validate=false -f https://github.com/jetstack/cert-manager/releases/download/v1.0.4/cert-manager.yaml In the time of writing this article the current version was v1.0.4 - you can change that to the latest release available of course. Here follows an example of the instalaltion of cert-manager: $ kubectl apply --validate=false -f https://github.com/jetstack/cert-manager/releases/download/v1.0.4/cert-manager.yaml customresourcedefinition.apiextensions.k8s.io/certificaterequests.cert-manager.io created customresourcedefinition.apiextensions.k8s.io/certificates.cert-manager.io created customresourcedefinition.apiextensions.k8s.io/challenges.acme.cert-manager.io created customresourcedefinition.apiextensions.k8s.io/clusterissuers.cert-manager.io created customresourcedefinition.apiextensions.k8s.io/issuers.cert-manager.io created customresourcedefinition.apiextensions.k8s.io/orders.acme.cert-manager.io created namespace/cert-manager created serviceaccount/cert-manager-cainjector created serviceaccount/cert-manager created serviceaccount/cert-manager-webhook created clusterrole.rbac.authorization.k8s.io/cert-manager-cainjector created clusterrole.rbac.authorization.k8s.io/cert-manager-controller-issuers created clusterrole.rbac.authorization.k8s.io/cert-manager-controller-clusterissuers created clusterrole.rbac.authorization.k8s.io/cert-manager-controller-certificates created clusterrole.rbac.authorization.k8s.io/cert-manager-controller-orders created clusterrole.rbac.authorization.k8s.io/cert-manager-controller-challenges created clusterrole.rbac.authorization.k8s.io/cert-manager-controller-ingress-shim created clusterrole.rbac.authorization.k8s.io/cert-manager-view created clusterrole.rbac.authorization.k8s.io/cert-manager-edit created clusterrolebinding.rbac.authorization.k8s.io/cert-manager-cainjector created clusterrolebinding.rbac.authorization.k8s.io/cert-manager-controller-issuers created clusterrolebinding.rbac.authorization.k8s.io/cert-manager-controller-clusterissuers created clusterrolebinding.rbac.authorization.k8s.io/cert-manager-controller-certificates created clusterrolebinding.rbac.authorization.k8s.io/cert-manager-controller-orders created clusterrolebinding.rbac.authorization.k8s.io/cert-manager-controller-challenges created clusterrolebinding.rbac.authorization.k8s.io/cert-manager-controller-ingress-shim created role.rbac.authorization.k8s.io/cert-manager-cainjector:leaderelection created role.rbac.authorization.k8s.io/cert-manager:leaderelection created role.rbac.authorization.k8s.io/cert-manager-webhook:dynamic-serving created rolebinding.rbac.authorization.k8s.io/cert-manager-cainjector:leaderelection created rolebinding.rbac.authorization.k8s.io/cert-manager:leaderelection created rolebinding.rbac.authorization.k8s.io/cert-manager-webhook:dynamic-serving created service/cert-manager created service/cert-manager-webhook created deployment.apps/cert-manager-cainjector created deployment.apps/cert-manager created deployment.apps/cert-manager-webhook created mutatingwebhookconfiguration.admissionregistration.k8s.io/cert-manager-webhook created validatingwebhookconfiguration.admissionregistration.k8s.io/cert-manager-webhook created Just after previous command check if the cert-manager pods are created: $ kubectl get pods -A NAMESPACE NAME READY STATUS RESTARTS AGE kube-system helm-install-traefik-p7jkh 0/1 Completed 0 49d kube-system metrics-server-7b4f8b595-bldsd 1/1 Running 3 49d kube-system local-path-provisioner-7ff9579c6-l6t6s 1/1 Running 3 49d kube-system svclb-traefik-r9q6r 2/2 Running 6 49d kube-system svclb-traefik-n6srr 2/2 Running 6 49d kube-system svclb-traefik-kxxn4 2/2 Running 6 49d kube-system coredns-66c464876b-vqrd6 1/1 Running 3 49d kube-system svclb-traefik-74k9f 2/2 Running 6 49d kube-system svclb-traefik-qlgn9 2/2 Running 6 49d kube-system traefik-5dd496474-4fwdm 1/1 Running 3 49d cert-manager cert-manager-86548b886-4xrbj 0/1 ContainerCreating 0 9s cert-manager cert-manager-cainjector-6d59c8d4f7-b2vdc 0/1 ContainerCreating 0 9s cert-manager cert-manager-webhook-578954cdd-lg5m4 0/1 ContainerCreating 0 9s After a minute or so check again with the wide option to see on which worker nodes the cert-managers pods are running: $ kubectl get pods -n cert-manager -o wide NAME READY STATUS RESTARTS AGE IP NODE NOMINATED NODE READINESS GATES cert-manager-cainjector-6d59c8d4f7-b2vdc 1/1 Running 0 21m 10.42.1.17 n5 <none> <none> cert-manager-webhook-578954cdd-lg5m4 1/1 Running 0 21m 10.42.0.19 n1 <none> <none> cert-manager-86548b886-4xrbj 1/1 Running 0 21m 10.42.5.10 n4 <none> <none> References \u00b6 cert-manager documentation cert-manager sources","title":"Raspberry Pi 4 Installing cert-manager on our cluster"},{"location":"pi-stories5/#pi4_stories","text":"","title":"PI4 Stories"},{"location":"pi-stories5/#raspberry_pi_4_cluster_series_-_installing_cert-manager_on_the_k3s_cluster","text":"As certificates are crucial in a kuberbetes cluster one of the first pods that one should install is cert-manager .","title":"Raspberry Pi 4 cluster Series - Installing cert-manager on the k3s cluster"},{"location":"pi-stories5/#installling_cert-manager","text":"Installaion is extremelt easy with the following command: kubectl apply --validate=false -f https://github.com/jetstack/cert-manager/releases/download/v1.0.4/cert-manager.yaml In the time of writing this article the current version was v1.0.4 - you can change that to the latest release available of course. Here follows an example of the instalaltion of cert-manager: $ kubectl apply --validate=false -f https://github.com/jetstack/cert-manager/releases/download/v1.0.4/cert-manager.yaml customresourcedefinition.apiextensions.k8s.io/certificaterequests.cert-manager.io created customresourcedefinition.apiextensions.k8s.io/certificates.cert-manager.io created customresourcedefinition.apiextensions.k8s.io/challenges.acme.cert-manager.io created customresourcedefinition.apiextensions.k8s.io/clusterissuers.cert-manager.io created customresourcedefinition.apiextensions.k8s.io/issuers.cert-manager.io created customresourcedefinition.apiextensions.k8s.io/orders.acme.cert-manager.io created namespace/cert-manager created serviceaccount/cert-manager-cainjector created serviceaccount/cert-manager created serviceaccount/cert-manager-webhook created clusterrole.rbac.authorization.k8s.io/cert-manager-cainjector created clusterrole.rbac.authorization.k8s.io/cert-manager-controller-issuers created clusterrole.rbac.authorization.k8s.io/cert-manager-controller-clusterissuers created clusterrole.rbac.authorization.k8s.io/cert-manager-controller-certificates created clusterrole.rbac.authorization.k8s.io/cert-manager-controller-orders created clusterrole.rbac.authorization.k8s.io/cert-manager-controller-challenges created clusterrole.rbac.authorization.k8s.io/cert-manager-controller-ingress-shim created clusterrole.rbac.authorization.k8s.io/cert-manager-view created clusterrole.rbac.authorization.k8s.io/cert-manager-edit created clusterrolebinding.rbac.authorization.k8s.io/cert-manager-cainjector created clusterrolebinding.rbac.authorization.k8s.io/cert-manager-controller-issuers created clusterrolebinding.rbac.authorization.k8s.io/cert-manager-controller-clusterissuers created clusterrolebinding.rbac.authorization.k8s.io/cert-manager-controller-certificates created clusterrolebinding.rbac.authorization.k8s.io/cert-manager-controller-orders created clusterrolebinding.rbac.authorization.k8s.io/cert-manager-controller-challenges created clusterrolebinding.rbac.authorization.k8s.io/cert-manager-controller-ingress-shim created role.rbac.authorization.k8s.io/cert-manager-cainjector:leaderelection created role.rbac.authorization.k8s.io/cert-manager:leaderelection created role.rbac.authorization.k8s.io/cert-manager-webhook:dynamic-serving created rolebinding.rbac.authorization.k8s.io/cert-manager-cainjector:leaderelection created rolebinding.rbac.authorization.k8s.io/cert-manager:leaderelection created rolebinding.rbac.authorization.k8s.io/cert-manager-webhook:dynamic-serving created service/cert-manager created service/cert-manager-webhook created deployment.apps/cert-manager-cainjector created deployment.apps/cert-manager created deployment.apps/cert-manager-webhook created mutatingwebhookconfiguration.admissionregistration.k8s.io/cert-manager-webhook created validatingwebhookconfiguration.admissionregistration.k8s.io/cert-manager-webhook created Just after previous command check if the cert-manager pods are created: $ kubectl get pods -A NAMESPACE NAME READY STATUS RESTARTS AGE kube-system helm-install-traefik-p7jkh 0/1 Completed 0 49d kube-system metrics-server-7b4f8b595-bldsd 1/1 Running 3 49d kube-system local-path-provisioner-7ff9579c6-l6t6s 1/1 Running 3 49d kube-system svclb-traefik-r9q6r 2/2 Running 6 49d kube-system svclb-traefik-n6srr 2/2 Running 6 49d kube-system svclb-traefik-kxxn4 2/2 Running 6 49d kube-system coredns-66c464876b-vqrd6 1/1 Running 3 49d kube-system svclb-traefik-74k9f 2/2 Running 6 49d kube-system svclb-traefik-qlgn9 2/2 Running 6 49d kube-system traefik-5dd496474-4fwdm 1/1 Running 3 49d cert-manager cert-manager-86548b886-4xrbj 0/1 ContainerCreating 0 9s cert-manager cert-manager-cainjector-6d59c8d4f7-b2vdc 0/1 ContainerCreating 0 9s cert-manager cert-manager-webhook-578954cdd-lg5m4 0/1 ContainerCreating 0 9s After a minute or so check again with the wide option to see on which worker nodes the cert-managers pods are running: $ kubectl get pods -n cert-manager -o wide NAME READY STATUS RESTARTS AGE IP NODE NOMINATED NODE READINESS GATES cert-manager-cainjector-6d59c8d4f7-b2vdc 1/1 Running 0 21m 10.42.1.17 n5 <none> <none> cert-manager-webhook-578954cdd-lg5m4 1/1 Running 0 21m 10.42.0.19 n1 <none> <none> cert-manager-86548b886-4xrbj 1/1 Running 0 21m 10.42.5.10 n4 <none> <none>","title":"Installling cert-manager"},{"location":"pi-stories5/#references","text":"cert-manager documentation cert-manager sources","title":"References"}]}